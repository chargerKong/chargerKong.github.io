<!DOCTYPE html>
<html lang="ch">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Kong Liangqian">
    
    <title>
        
            pytorch 自动求导 |
        
        大杂烩
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/wuwuwu.jpg">
    
<link rel="stylesheet" href="/css/font-awesome.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"chargerkong.github.io","root":"/","language":"ch"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#0066CC","avatar":"/images/wuwuwu.jpg","favicon":"/images/wuwuwu.jpg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":false,"background_img":"/images/bg.svg","description":"Keep writing and Keep loving."},"scroll":{"progress_bar":{"enable":false},"percent":{"enable":false}}},"local_search":{"enable":false,"preload":false},"code_copy":{"enable":false,"style":"default"},"pjax":{"enable":false},"lazyload":{"enable":false},"version":"3.4.2"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
<meta name="generator" content="Hexo 5.4.1"></head>


<body>
<div class="progress-bar-container">
    

    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            <a class="logo-title" href="/">
                大杂烩
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/tags"
                            >
                                TAGS
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/about"
                            >
                                ABOUT
                            </a>
                        </li>
                    
                    
                </ul>
            </div>
            <div class="mobile">
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/tags">TAGS</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/about">ABOUT</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">pytorch 自动求导</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/wuwuwu.jpg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Kong Liangqian</span>
                        
                            <span class="author-label">Lv6</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;2022-10-27 18:38:29
    </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/pytorch/">pytorch</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
    
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <p>内容来自于<a class="link"   target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/67184419" >https://zhuanlan.zhihu.com/p/67184419<i class="fas fa-external-link-alt"></i></a></p>
<h1 id="requires-grad简介"><a href="#requires-grad简介" class="headerlink" title="requires_grad简介"></a>requires_grad简介</h1><p>Pytorch中的变量可以分为需要求导的，和不需要求导的，可以通过<code>requires_grad</code>来查看一个张量是否需要求导，一个简单的张量默认是不需要求导的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">4</span>]: inp = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">5</span>]: inp.requires_grad</span><br><span class="line">Out[<span class="number">5</span>]: <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>但是在nn中的所有的参数默认是需要求导的，比如</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">17</span>]: con1 = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">1</span>, kernel_size=<span class="number">2</span>,stride=<span class="number">1</span>,padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: con1.weight</span><br><span class="line">Out[<span class="number">18</span>]: </span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([[[[-<span class="number">0.3100</span>, -<span class="number">0.3029</span>],</span><br><span class="line">          [-<span class="number">0.4663</span>, -<span class="number">0.0912</span>]]]], requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: con1.bias</span><br><span class="line">Out[<span class="number">19</span>]: </span><br><span class="line">Parameter containing:</span><br><span class="line">tensor([<span class="number">0.4589</span>], requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>在张量间的计算过程中，如果在所有输入中，有一个输入需要求导，那么输出一定会需要求导；相反，只有当所有输入都不需要求导的时候，输出才会不需要。</p>
<h1 id="requires-grad-冻结参数"><a href="#requires-grad-冻结参数" class="headerlink" title="requires_grad 冻结参数"></a>requires_grad 冻结参数</h1><p>在训练的过程中冻结部分网络，让这些层的参数不再更新，这在迁移学习中很有用处</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">model = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用一个新的 fc 层来取代之前的全连接层</span></span><br><span class="line"><span class="comment"># 因为新构建的 fc 层的参数默认 requires_grad=True</span></span><br><span class="line">model.fc = nn.Linear(<span class="number">512</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 只更新 fc 层的参数</span></span><br><span class="line">optimizer = optim.SGD(model.fc.parameters(), lr=<span class="number">1e-2</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过这样，我们就冻结了 resnet 前边的所有层，</span></span><br><span class="line"><span class="comment"># 在训练过程中只更新最后的 fc 层中的参数。</span></span><br></pre></td></tr></table></figure>
<h1 id="grad计算举例"><a href="#grad计算举例" class="headerlink" title="grad计算举例"></a>grad计算举例</h1><h2 id="y-sum-i-2x-i"><a href="#y-sum-i-2x-i" class="headerlink" title="$y = \sum_i 2x_i$"></a>$y = \sum_i 2x_i$</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([-<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = torch.<span class="built_in">sum</span>(x * <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">y.backward()</span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br></pre></td></tr></table></figure>
<p>结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([2., 2., 2.])</span><br></pre></td></tr></table></figure>
<p>对应运算</p>
<script type="math/tex; mode=display">
y =2x_1 + 2x_2+2x_3\\
\frac{\partial y}{\partial x_1} = 2, \frac{\partial y}{\partial x_2} = 2,\frac{\partial y}{\partial x_3} = 2</script><h2 id="y-2x"><a href="#y-2x" class="headerlink" title="$y = 2x$"></a>$y = 2x$</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([-<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = x * <span class="number">2</span></span><br><span class="line"></span><br><span class="line">y.backward()</span><br></pre></td></tr></table></figure>
<p>结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: grad can be implicitly created only <span class="keyword">for</span> scalar outputs</span><br></pre></td></tr></table></figure>
<p>这是因为，在<code>backward()</code>这样操作，只有当y是标量才可以进行求导，而我们给出的y是三维的，因此不可以求导</p>
<p>代码修改</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x &#x3D; torch.tensor([-1.0, 0.0, 1.0], requires_grad&#x3D;True)</span><br><span class="line">y &#x3D; x * 2</span><br><span class="line"></span><br><span class="line">y.backward(torch.tensor([1, 1, 1)]))</span><br><span class="line">print(x.grad)</span><br></pre></td></tr></table></figure>
<p>结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([2., 2., 2.])</span><br></pre></td></tr></table></figure>
<p>实际运算</p>
<script type="math/tex; mode=display">
y =2x\\
\frac{\partial y}{\partial x_1} = 2, \frac{\partial y}{\partial x_2} = 2,\frac{\partial y}{\partial x_3} = 2</script><p>在backward里面添加的数，为梯度的系数，如果是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.backward(torch.tensor([1,2,2]))</span><br><span class="line">x.grad</span><br></pre></td></tr></table></figure>
<p>结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([2., 4., 4.])</span><br></pre></td></tr></table></figure>
<h2 id="y-ax"><a href="#y-ax" class="headerlink" title="$y = ax$"></a>$y = ax$</h2><p>注意，该例子里，求导对象是变量$a$, 而不是$x$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([-<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>])</span><br><span class="line">a = torch.tensor(<span class="number">2</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = torch.<span class="built_in">sum</span>(x * a)</span><br><span class="line"></span><br><span class="line">y.backward()</span><br><span class="line"><span class="built_in">print</span>(a.grad)</span><br></pre></td></tr></table></figure>
<p>结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(0)</span><br></pre></td></tr></table></figure>
<p>对应运算</p>
<script type="math/tex; mode=display">
y =ax_1 + ax_2+ax_3\\
\frac{\partial y}{\partial a} = \frac{\partial y}{\partial x_1} +\frac{\partial y}{\partial x_2}+\frac{\partial y}{\partial x_3} = x_1+x_2+x_3=0</script><h1 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h1><p>上述例子只可以求导一次，看下面例子</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x &#x3D; torch.tensor([-1.0, 0.0, 1.0], requires_grad&#x3D;True)</span><br><span class="line"></span><br><span class="line">y &#x3D; x * 2</span><br><span class="line"></span><br><span class="line">y.backward(torch.tensor([1,2,2]), retain_graph&#x3D;True)</span><br><span class="line">y.backward(torch.tensor([1,2,2]), retain_graph&#x3D;True)</span><br><span class="line"></span><br><span class="line">print(x.grad)</span><br></pre></td></tr></table></figure>
<p>结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([4., 8., 8.])</span><br></pre></td></tr></table></figure>
<p>第二次求导会迭代第一次的结果。</p>
<p>/如果求导两次，必须在第二次求导前使变量的导数为0</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x &#x3D; torch.tensor([-1.0, 0.0, 1.0], requires_grad&#x3D;True)</span><br><span class="line"></span><br><span class="line">y &#x3D; x * 2</span><br><span class="line"></span><br><span class="line">y.backward(torch.tensor([1,2,2]), retain_graph&#x3D;True)</span><br><span class="line">x.grad.zero_()</span><br><span class="line">y.backward(torch.tensor([1,2,2]), retain_graph&#x3D;True)</span><br><span class="line"></span><br><span class="line">print(x.grad)</span><br></pre></td></tr></table></figure>
<p>结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([2., 4., 4.])</span><br></pre></td></tr></table></figure>
<h1 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create Tensors to hold input and outputs.</span></span><br><span class="line">x = torch.linspace(-math.pi, math.pi, <span class="number">2000</span>)</span><br><span class="line">y = torch.sin(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># For this example, the output y is a linear function of (x, x^2, x^3), so</span></span><br><span class="line"><span class="comment"># we can consider it as a linear layer neural network. Let&#x27;s prepare the</span></span><br><span class="line"><span class="comment"># tensor (x, x^2, x^3).</span></span><br><span class="line">p = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">xx = x.unsqueeze(-<span class="number">1</span>).<span class="built_in">pow</span>(p)</span><br><span class="line"></span><br><span class="line"><span class="comment"># In the above code, x.unsqueeze(-1) has shape (2000, 1), and p has shape</span></span><br><span class="line"><span class="comment"># (3,), for this case, broadcasting semantics will apply to obtain a tensor</span></span><br><span class="line"><span class="comment"># of shape (2000, 3)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use the nn package to define our model as a sequence of layers. nn.Sequential</span></span><br><span class="line"><span class="comment"># is a Module which contains other Modules, and applies them in sequence to</span></span><br><span class="line"><span class="comment"># produce its output. The Linear Module computes output from input using a</span></span><br><span class="line"><span class="comment"># linear function, and holds internal Tensors for its weight and bias.</span></span><br><span class="line"><span class="comment"># The Flatten layer flatens the output of the linear layer to a 1D tensor,</span></span><br><span class="line"><span class="comment"># to match the shape of `y`.</span></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(<span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">    torch.nn.Flatten(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The nn package also contains definitions of popular loss functions; in this</span></span><br><span class="line"><span class="comment"># case we will use Mean Squared Error (MSE) as our loss function.</span></span><br><span class="line">loss_fn = torch.nn.MSELoss(reduction=<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2000</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Forward pass: compute predicted y by passing x to the model. Module objects</span></span><br><span class="line">    <span class="comment"># override the __call__ operator so you can call them like functions. When</span></span><br><span class="line">    <span class="comment"># doing so you pass a Tensor of input data to the Module and it produces</span></span><br><span class="line">    <span class="comment"># a Tensor of output data.</span></span><br><span class="line">    y_pred = model(xx)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute and print loss. We pass Tensors containing the predicted and true</span></span><br><span class="line">    <span class="comment"># values of y, and the loss function returns a Tensor containing the</span></span><br><span class="line">    <span class="comment"># loss.</span></span><br><span class="line">    loss = loss_fn(y_pred, y)</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">100</span> == <span class="number">99</span>:</span><br><span class="line">        <span class="built_in">print</span>(t, loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Zero the gradients before running the backward pass.</span></span><br><span class="line">    model.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backward pass: compute gradient of the loss with respect to all the learnable</span></span><br><span class="line">    <span class="comment"># parameters of the model. Internally, the parameters of each Module are stored</span></span><br><span class="line">    <span class="comment"># in Tensors with requires_grad=True, so this call will compute gradients for</span></span><br><span class="line">    <span class="comment"># all learnable parameters in the model.</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update the weights using gradient descent. Each parameter is a Tensor, so</span></span><br><span class="line">    <span class="comment"># we can access its gradients like we did before.</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">            param -= learning_rate * param.grad</span><br><span class="line"></span><br><span class="line"><span class="comment"># You can access the first layer of `model` like accessing the first item of a list</span></span><br><span class="line">linear_layer = model[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># For linear layer, its parameters are stored as `weight` and `bias`.</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Result: y = <span class="subst">&#123;linear_layer.bias.item()&#125;</span> + <span class="subst">&#123;linear_layer.weight[:, <span class="number">0</span>].item()&#125;</span> x + <span class="subst">&#123;linear_layer.weight[:, <span class="number">1</span>].item()&#125;</span> x^2 + <span class="subst">&#123;linear_layer.weight[:, <span class="number">2</span>].item()&#125;</span> x^3&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

        </div>

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/2022/11/10/221106%20Linear%E5%AF%B9%E8%B1%A1%E4%BD%BF%E7%94%A8/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Linear对象使用</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/2022/05/07/230507%E6%A2%AF%E5%BA%A6%E6%9B%B4%E6%96%B0/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">梯度更新</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
            <div class="comment-container">
                <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments">&nbsp;Comments</i>
    </div>
    

        
            /* variables */
$gt-color-main := #6190e8
$gt-color-sub := #a1a1a1
$gt-color-loader := #999999
$gt-color-error := #ff3860
$gt-color-hr :=  #E9E9E9
$gt-color-comment-txt := #333333
$gt-color-link-active := #333333
$gt-color-btn := #ffffff
$gt-size-base := 16px // default font-size
$gt-size-border-radius := 5px
$gt-breakpoint-mobile := 479px
$gt-mask-z-index := 9999

/* functions & mixins */
clearfix() {
  &:before,
  &:after {
    content: " ";
    display: table;
  }
  &:after { clear: both; }
}
em($px, $base-size = $gt-size-base)
  u = unit($px)
  if (u is 'px')
    unit($px / $base-size, 'em')
  else
    unit($px, u)

mobile()
  @media (max-width: $gt-breakpoint-mobile)
    {block}

/* variables - calculated */
$gt-size-loader-dot := em(6px)
$gt-size-loader := em(28px)
$gt-size-avatar := em(50px)
$gt-size-avatar-mobi := em(32px)

/* styles */
// Put everything under container to avoid style conflicts
.comments-container
  .gt-container
    box-sizing: border-box
    *
      box-sizing: border-box
    font-size: $gt-size-base
    // common
    a
      color: $gt-color-main
      &:hover
        color: lighten($gt-color-main, 20%)
        border-color: lighten($gt-color-main, 20%)
      &.is--active
        color: $gt-color-link-active
        cursor: default !important
        &:hover
          color: $gt-color-link-active
    .hide
      display: none !important
    // icons
    .gt-svg
      display: inline-block
      width: em(16px)
      height: em(16px)
      vertical-align: sub
      svg
        width: 100%
        height: 100%
        fill: $gt-color-main
    .gt-ico
      display: inline-block
      &-text
        margin-left: em(5px)
      &-github
        width: 100%
        height: 100%
        .gt-svg
          width: 100%
          height: 100%
        svg
          fill: inherit
    /* loader */
    .gt-spinner
      position: relative
      &::before
        content: ''
        box-sizing: border-box
        position: absolute
        top: 3px
        width: em(12px)
        height: em(12px)
        margin-top: em(-3px)
        margin-left: em(-6px)
        border-radius: 50%
        border: 1px solid $gt-color-btn
        border-top-color: $gt-color-main
        animation: gt-kf-rotate .6s linear infinite

    .gt-loader
      position: relative
      border: 1px solid $gt-color-loader
      animation: ease gt-kf-rotate 1.5s infinite
      display: inline-block
      font-style: normal
      width: $gt-size-loader
      height: $gt-size-loader
      //font-size: $gt-size-loader
      line-height: $gt-size-loader
      border-radius: 50%
      &:before
        content: ''
        position: absolute
        display: block
        top: 0
        left: 50%
        margin-top: -($gt-size-loader-dot / 2)
        margin-left: -($gt-size-loader-dot / 2)
        width: $gt-size-loader-dot
        height: $gt-size-loader-dot
        background-color: $gt-color-loader
        border-radius: 50%
    // avatar
    .gt-avatar
      display: inline-block
      width: $gt-size-avatar
      height: $gt-size-avatar
      +mobile()
        width: $gt-size-avatar-mobi
        height: $gt-size-avatar-mobi
      img
        width: 100%
        height: auto
        border-radius: 3px
      &-github
        width: $gt-size-avatar - em(2px)
        height: $gt-size-avatar - em(2px)
        cursor: pointer
        +mobile()
          width: $gt-size-avatar-mobi - em(2px)
          height: $gt-size-avatar-mobi - em(2px)
    // button
    .gt-btn
      padding: em(12px) em(20px)
      display: inline-block
      line-height: 1
      text-decoration: none
      white-space: nowrap
      cursor: pointer
      border: 1px solid $gt-color-main
      border-radius: $gt-size-border-radius
      background-color: $gt-color-main
      color: $gt-color-btn
      outline: none
      font-size: em(12px)
      &-text
        font-weight: 400
      &-loading
        position: relative
        margin-left: em(8px)
        display: inline-block
        width: em(12px)
        height: em(16px)
        vertical-align: top
      &.is--disable
        cursor: not-allowed
        opacity: 0.5
      &-login
        margin-right: 0
      &-preview
        background-color: var(--background-color)
        color: $gt-color-main
        &:hover
          background-color: var(--second-background-color)
      &-public
        &:hover
          background-color: lighten($gt-color-main, 20%)
          border-color: lighten($gt-color-main, 20%)
  &-loadmore
  // loadmore

  /* error */
  .gt-error
    text-align: center
    margin: em(10px)
    color: $gt-color-error

  /* initing */
  .gt-initing
    padding: em(20px) 0
    text-align: center
    &-text
      margin: em(10px) auto
      font-size: 92%

  /* no int */
  .gt-no-init
    padding: em(20px) 0
    text-align: center

  /* link */
  .gt-link
    border-bottom: 1px dotted $gt-color-main
    &-counts, &-project
      text-decoration: none

  /* meta */
  .gt-meta
    margin: em(20px) 0
    padding: em(16px) 0
    position: relative
    border-bottom: 1px solid $gt-color-hr
    font-size: em(16px)
    z-index: 10
    clearfix()

  .gt-counts
    margin: 0 em(10px) 0 0
    color: var(--default-text-color)

  .gt-user
    float: right
    margin: 0
    font-size: 92%
    &-pic
      width: 16px
      height: 16px
      vertical-align: top
      margin-right: em(8px)
    &-inner
      display: inline-block
      cursor: pointer
      .gt-user-name
        color: var(--default-text-color)

    .gt-ico
      margin: 0 0 0 em(5px)
      svg
        fill: var(--default-text-color)
    .is--poping
      .gt-ico
        svg
          fill: $gt-color-main

  .gt-version
    color: $gt-color-sub
    margin-left: em(6px)

  .gt-copyright
    margin: 0 em(15px) em(8px)
    border-top: 1px solid var(--border-color)
    padding-top: em(8px)

  /* popup */
  .gt-popup
    position: absolute
    right: 0
    top: em(38px)
    background: var(--background-color)
    display: inline-block
    border: 1px solid var(--border-color)
    padding: em(10px) 0
    font-size: em(14px)
    letter-spacing: .5px
    .gt-action
      cursor: pointer
      display: block
      margin: em(8px) 0
      padding: 0 em(18px)
      position: relative
      text-decoration: none
      &.is--active
        &:before
          content: ''
          width: em(4px)
          height: em(4px)
          background: $gt-color-main
          position: absolute
          left: em(8px)
          top: em(7px)
  /* header */
  .gt-header
    position: relative
    display: flex
    &-comment
      flex: 1
      margin-left: em(20px)
      +mobile()
        margin-left: em(14px)
    &-textarea
      padding: em(12px)
      display: block
      box-sizing: border-box
      width: 100%
      min-height: em(82px)
      max-height: em(240px)
      border-radius: $gt-size-border-radius
      border: 1px solid var(--border-color)
      font-size: em(14px)
      word-wrap: break-word
      resize: vertical
      color: var(--default-text-color)
      background-color: var(--fourth-text-color)
      outline: none
      transition: all 0.25s ease
      &:hover
        background-color: var(--background-color)
    &-preview
      padding: em(12px)
      border-radius: $gt-size-border-radius
      border: 1px solid var(--border-color)
      background-color: var(--background-color)
    &-controls
      position: relative
      margin: em(12px) 0 0
      clearfix()
      +mobile()
        margin: 0
      &-tip
        font-size: em(14px)
        color: $gt-color-main
        text-decoration: none
        vertical-align: sub
        +mobile()
          display: none
      .gt-btn
        float: right
        margin-left: em(20px)
        +mobile()
          float: none
          width: 100%
          margin: em(12px) 0 0

  &:after
    content: ''
    position: fixed
    bottom: 100%
    left: 0
    right: 0
    top: 0
    opacity: 0
  &.gt-input-focused
    position: relative
    &:after
      content: ''
      position: fixed
      bottom: 0
      left: 0
      right: 0
      top: 0
      background: #000
      opacity: 0.6
      transition: opacity .3s, bottom 0s
      z-index: $gt-mask-z-index
    .gt-header-comment
      z-index: $gt-mask-z-index + 1

  /* comments */
  .gt-comments
    padding-top: em(20px)
    &-null
      text-align: center
    &-controls
      margin: em(20px) 0
      text-align: center

  /* comment */
  .gt-comment
    position: relative
    padding: em(10px) 0
    display: flex
    &-content
      flex: 1
      margin-left: em(20px)
      padding: em(12px) em(16px)
      background-color: var(--second-background-color)
      overflow: auto
      transition: all ease 0.25s
      +mobile()
        margin-left: em(14px)
        padding: em(10px) em(12px)
    &-header
      margin-bottom: em(8px)
      font-size: em(14px)
      position: relative
    &-block-1
      float: right
      height: em(22px)
      width: em(32px)
    &-block-2
      float: right
      height: em(22px)
      width: em(64px)
    &-username
      font-weight: 500
      color: $gt-color-main
      text-decoration: none
      &:hover
        text-decoration: underline
    &-text
      margin-left: em(8px)
      color: $gt-color-sub
    &-date
      margin-left: em(8px)
      color: $gt-color-sub
    &-like, &-edit, &-reply
      position: absolute
      height: em(22px)
      &:hover
        cursor: pointer
    &-like
      top: 0
      right: em(32px)
    &-edit, &-reply
      top: 0
      right: 0
    &-body
      //color: $gt-color-comment-txt !important
      color: var(--second-text-color) !important
      .email-hidden-toggle a
        display: inline-block;
        height: 12px;
        padding: 0 9px;
        font-size: 12px;
        font-weight: 600;
        line-height: 6px;
        color: #444d56;
        text-decoration: none;
        vertical-align: middle;
        background: #dfe2e5;
        border-radius: 1px;
        &:hover
          background-color: #c6cbd1;
      .email-hidden-reply
        display: none;
        white-space: pre-wrap
        .email-signature-reply
          padding: 0 15px;
          margin: 15px 0;
          color: #586069;
          border-left: 4px solid #dfe2e5;
      .email-hidden-reply.expanded
        display: block
    &-admin
      .gt-comment-content
        background-color: var(--fourth-text-color)

  @keyframes gt-kf-rotate
    0%
      transform: rotate(0)
    100%
      transform: rotate(360deg)


        
    
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span>&nbsp;-&nbsp;
            
            2024&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Kong Liangqian</a>
        </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.2</a>
        </div>
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fas fa-comment"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#requires-grad%E7%AE%80%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">requires_grad简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#requires-grad-%E5%86%BB%E7%BB%93%E5%8F%82%E6%95%B0"><span class="nav-number">2.</span> <span class="nav-text">requires_grad 冻结参数</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#grad%E8%AE%A1%E7%AE%97%E4%B8%BE%E4%BE%8B"><span class="nav-number">3.</span> <span class="nav-text">grad计算举例</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#y-sum-i-2x-i"><span class="nav-number">3.1.</span> <span class="nav-text">$y &#x3D; \sum_i 2x_i$</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#y-2x"><span class="nav-number">3.2.</span> <span class="nav-text">$y &#x3D; 2x$</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#y-ax"><span class="nav-number">3.3.</span> <span class="nav-text">$y &#x3D; ax$</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B3%A8%E6%84%8F"><span class="nav-number">4.</span> <span class="nav-text">注意</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A1%88%E4%BE%8B"><span class="nav-number">5.</span> <span class="nav-text">案例</span></a></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>








<div class="post-scripts">
    
        
<script src="/js/left-side-toggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/toc.js"></script>

    
</div>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


</body>
</html>
